{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBtnk_0JTqmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c714495e-991a-40fb-8325-4789f8e763ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas pyarrow\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Checks the security of the API and the data extraction method.*\n"
      ],
      "metadata": {
        "id": "3tXY_8ysb7qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def authentication():\n",
        "    \"\"\"\n",
        "    Simulates an authentication check.\n",
        "\n",
        "    Returns:\n",
        "    - bool: True if authentication is successful, False otherwise.\n",
        "    \"\"\"\n",
        "    return True"
      ],
      "metadata": {
        "id": "DrkiL-XI3ZdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Define a function to extract the data from the Parquet file and store in a dataframe*"
      ],
      "metadata": {
        "id": "EY9FMUAEcSaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def api_call(file_path='/content/home_assignment_raw_data.parquet'):\n",
        "    \"\"\"\n",
        "    Authenticates and reads data from a parquet file.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path(str): Path to the parquet file.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame containing the parquet file data if authentication is successful.\n",
        "\n",
        "    Raises:\n",
        "    - Exception: Raises an exception if authentication fails.\n",
        "    \"\"\"\n",
        "    auth = authentication()\n",
        "    if auth:\n",
        "        df = pd.read_parquet(file_path)\n",
        "        return df\n",
        "    else:\n",
        "        raise Exception(\"Authentication failed.\")"
      ],
      "metadata": {
        "id": "j-ybOOvRVrXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert data types of the columns**\n",
        "- *converts the data types of the columns to appropriate data types.*"
      ],
      "metadata": {
        "id": "sswk5COBfKmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_quality(df):\n",
        "    \"\"\"\n",
        "    Ensures data quality by converting column types.\n",
        "\n",
        "    Parameters:\n",
        "    - df(pd.DataFrame): DataFrame to be processed.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: Processed DataFrame with corrected data types.\n",
        "    \"\"\"\n",
        "    df['client_id'] = df['client_id'].astype(str)\n",
        "    df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
        "    df['ext_dev_ref'] = df['ext_dev_ref'].astype(str)\n",
        "    df['resolution'] = df['resolution'].astype(str)\n",
        "    return df"
      ],
      "metadata": {
        "id": "L0TbH90reqel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Resolution into Unit and Scale**\n",
        "- Splits Resolution column into Scale and Units for better analytical and quering purpose.\n",
        "- Flattening the \"energy_consumption\" list to separate columns to help to individually analyze time series data and helpful to quering when building customer insights."
      ],
      "metadata": {
        "id": "mCnJ0kO_hgf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(df):\n",
        "    \"\"\"\n",
        "    Extracts features from the resolution and energy consumption columns.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): DataFrame to be processed.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with extracted features.\n",
        "    \"\"\"\n",
        "    df[['Scale', 'Unit']] = df['resolution'].str.extract(r'(\\d+)(\\D+)')\n",
        "    df['Scale'] = df['Scale'].astype(int)\n",
        "    new_df = pd.concat([df.drop(columns=['energy_consumption']),\n",
        "                          pd.DataFrame(df['energy_consumption'].tolist()).add_prefix('Hour_')], axis=1)\n",
        "    return new_df"
      ],
      "metadata": {
        "id": "9FfIsw6lhfes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "try:\n",
        "    df = api_call()\n",
        "    df = data_quality(df)\n",
        "    df = feature_extraction(df)\n",
        "    print(df.head())\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS7wFxTnaegK",
        "outputId": "aa10480e-c04e-4303-aa6e-9f2227ffe1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  client_id       date   ext_dev_ref resolution  Scale Unit  Hour_0  Hour_1  \\\n",
            "0    111111 2022-01-01  ext_device_1      60min     60  min   100.0   100.0   \n",
            "1    111111 2022-01-02  ext_device_1      60min     60  min   100.0   100.0   \n",
            "2    111111 2022-01-03  ext_device_1      60min     60  min   100.0   100.0   \n",
            "3    111111 2022-01-04  ext_device_1      60min     60  min   100.0   100.0   \n",
            "4    111111 2022-01-05  ext_device_1      60min     60  min   100.0   100.0   \n",
            "\n",
            "   Hour_2  Hour_3  ...  Hour_14  Hour_15  Hour_16  Hour_17  Hour_18  Hour_19  \\\n",
            "0   100.0   100.0  ...    100.0    100.0    100.0    100.0    100.0    100.0   \n",
            "1   100.0   100.0  ...    100.0    100.0    100.0    100.0    100.0    100.0   \n",
            "2   100.0   100.0  ...    100.0    100.0    100.0    100.0    100.0    100.0   \n",
            "3   100.0   100.0  ...    100.0    100.0    100.0    100.0    100.0    100.0   \n",
            "4   100.0   100.0  ...    100.0    100.0    100.0    100.0    100.0    100.0   \n",
            "\n",
            "   Hour_20  Hour_21  Hour_22  Hour_23  \n",
            "0    100.0    100.0    100.0    100.0  \n",
            "1    100.0    100.0    100.0    100.0  \n",
            "2    100.0    100.0    100.0    100.0  \n",
            "3    100.0    100.0    100.0    100.0  \n",
            "4    100.0    100.0    100.0    100.0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/New_DF_data.csv'\n",
        "df.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "p4AtujTGmdQR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}